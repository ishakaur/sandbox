{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Homework: https://work.caltech.edu/homework/hw8.pdf\n",
    "<p>\n",
    "\n",
    "&#x2714;\n",
    "Answers:\n",
    "1. e, but not so sure --> d\n",
    "2. a &#x2714;\n",
    "3. a &#x2714;\n",
    "4. c &#x2714;\n",
    "5. d &#x2714;\n",
    "6. b &#x2714;\n",
    "7. b &#x2714;\n",
    "8. c &#x2714;\n",
    "9. e &#x2714;\n",
    "10. c &#x2714;\n",
    "\n",
    "<p>\n",
    "Answer key: https://work.caltech.edu/homework/hw8_sol.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_fwf('http://www.amlbook.com/data/zip/features.train', header=None, \n",
    "                    names=['digit', 'intensity', 'symmetry'])\n",
    "test = pd.read_fwf('http://www.amlbook.com/data/zip/features.test', header=None, \n",
    "                   names=['digit', 'intensity', 'symmetry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>intensity</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.903443</td>\n",
       "      <td>0.254481</td>\n",
       "      <td>-3.403779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.996386</td>\n",
       "      <td>0.092944</td>\n",
       "      <td>1.492641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046820</td>\n",
       "      <td>-7.326688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185008</td>\n",
       "      <td>-4.466406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.245305</td>\n",
       "      <td>-3.581875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.313678</td>\n",
       "      <td>-2.560031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.655941</td>\n",
       "      <td>-0.119500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             digit    intensity     symmetry\n",
       "count  7291.000000  7291.000000  7291.000000\n",
       "mean      3.903443     0.254481    -3.403779\n",
       "std       2.996386     0.092944     1.492641\n",
       "min       0.000000     0.046820    -7.326688\n",
       "25%       1.000000     0.185008    -4.466406\n",
       "50%       4.000000     0.245305    -3.581875\n",
       "75%       7.000000     0.313678    -2.560031\n",
       "max       9.000000     0.655941    -0.119500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>intensity</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.341092</td>\n",
       "      <td>-4.528937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.444131</td>\n",
       "      <td>-5.496812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.231002</td>\n",
       "      <td>-2.886750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>-3.534375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.291936</td>\n",
       "      <td>-4.352062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   digit  intensity  symmetry\n",
       "0      6   0.341092 -4.528937\n",
       "1      5   0.444131 -5.496812\n",
       "2      4   0.231002 -2.886750\n",
       "3      7   0.200275 -3.534375\n",
       "4      3   0.291936 -4.352062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>intensity</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.850523</td>\n",
       "      <td>0.267609</td>\n",
       "      <td>-3.450593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.018484</td>\n",
       "      <td>0.099506</td>\n",
       "      <td>1.479704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057043</td>\n",
       "      <td>-7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191987</td>\n",
       "      <td>-4.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.256168</td>\n",
       "      <td>-3.605625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.332122</td>\n",
       "      <td>-2.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.642658</td>\n",
       "      <td>-0.189062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             digit    intensity     symmetry\n",
       "count  2007.000000  2007.000000  2007.000000\n",
       "mean      3.850523     0.267609    -3.450593\n",
       "std       3.018484     0.099506     1.479704\n",
       "min       0.000000     0.057043    -7.700000\n",
       "25%       1.000000     0.191987    -4.482000\n",
       "50%       4.000000     0.256168    -3.605625\n",
       "75%       6.000000     0.332122    -2.597500\n",
       "max       9.000000     0.642658    -0.189062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>intensity</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.272178</td>\n",
       "      <td>-4.847937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.265133</td>\n",
       "      <td>-5.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.335926</td>\n",
       "      <td>-2.921562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.264850</td>\n",
       "      <td>-4.156625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.345338</td>\n",
       "      <td>-6.718438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   digit  intensity  symmetry\n",
       "0      9   0.272178 -4.847937\n",
       "1      6   0.265133 -5.102000\n",
       "2      3   0.335926 -2.921562\n",
       "3      6   0.264850 -4.156625\n",
       "4      6   0.345338 -6.718438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.describe())\n",
    "display(train.head())\n",
    "display(test.describe())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_in = train.iloc[:, 1:]\n",
    "y_in = train.iloc[:, 0]\n",
    "\n",
    "X_out = test.iloc[:, 1:]\n",
    "y_out = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_E_in(target, X_in, y_in):\n",
    "    classifier = svm.SVC(C=0.01, # Penalty parameter C of the error term.\n",
    "                            kernel='poly', # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used\n",
    "                            degree=2, # Degree of the polynomial kernel, ignored by others\n",
    "                            gamma=1.0, # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "                            coef0=1.0, # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "                            shrinking=False, # Whether to use the shrinking heuristic.\n",
    "                            probability=False, # Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.\n",
    "                            tol=0.001, # Tolerance for stopping criterion.\n",
    "                            cache_size=200, # Specify the size of the kernel cache (in MB).\n",
    "                            class_weight=None, \n",
    "                            verbose=False, \n",
    "                            max_iter=-1, \n",
    "                            decision_function_shape='ovr', # Whether to return a one-vs-rest (‘ovo’) ecision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.18.\n",
    "                            random_state=None)\n",
    "    y = y_in.copy()\n",
    "    y[y != target] = -1\n",
    "    classifier.fit(X_in, y)\n",
    "    y_pred = classifier.predict(X_in)\n",
    "    misclassified = y_pred != y\n",
    "    return classifier, sum(misclassified)*100./len(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in(0) = 10.59%, N_SVs = [1090 1089]\n",
      "E_in(2) = 10.03%, N_SVs = [1258  731]\n",
      "E_in(4) = 8.94%, N_SVs = [1223  652]\n",
      "E_in(6) = 9.11%, N_SVs = [1228  664]\n",
      "E_in(8) = 7.43%, N_SVs = [1239  542]\n"
     ]
    }
   ],
   "source": [
    "for target in [0, 2, 4, 6, 8]:\n",
    "    clf, E_in = get_E_in(target, X_in, y_in)\n",
    "    print \"E_in({}) = {:.2f}%, N_SVs = {}\".format(target, E_in, clf.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in(1) = 1.44%, N_SVs = [193 193]\n",
      "E_in(3) = 9.02%, N_SVs = [1288  658]\n",
      "E_in(5) = 7.63%, N_SVs = [1046  556]\n",
      "E_in(7) = 8.85%, N_SVs = [1070  645]\n",
      "E_in(9) = 8.83%, N_SVs = [1341  644]\n"
     ]
    }
   ],
   "source": [
    "for target in [1, 3, 5, 7, 9]:\n",
    "    clf, E_in = get_E_in(target, X_in, y_in)\n",
    "    print \"E_in({}) = {:.2f}%, N_SVs = {}\".format(target, E_in, clf.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in support vectors is: 1793\n"
     ]
    }
   ],
   "source": [
    "print \"Difference in support vectors is: {}\".format(1090 + 1089 - 193 - 193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 2, C: 0.0001, SV_s: [118 118], E_in: 0.90, E_out: 1.65\n",
      "Q: 2, C: 0.0010, SV_s: [38 38], E_in: 0.45, E_out: 1.65\n",
      "Q: 2, C: 0.0100, SV_s: [17 17], E_in: 0.45, E_out: 1.89\n",
      "Q: 2, C: 0.1000, SV_s: [12 12], E_in: 0.45, E_out: 1.89\n",
      "Q: 2, C: 1.0000, SV_s: [12 12], E_in: 0.32, E_out: 1.89\n",
      "Q: 5, C: 0.0001, SV_s: [13 13], E_in: 0.45, E_out: 1.89\n",
      "Q: 5, C: 0.0010, SV_s: [12 13], E_in: 0.45, E_out: 2.12\n",
      "Q: 5, C: 0.0100, SV_s: [11 12], E_in: 0.38, E_out: 2.12\n",
      "Q: 5, C: 0.1000, SV_s: [11 14], E_in: 0.32, E_out: 1.89\n",
      "Q: 5, C: 1.0000, SV_s: [10 11], E_in: 0.32, E_out: 2.12\n"
     ]
    }
   ],
   "source": [
    "def computeError(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    misclassified = y_pred != y\n",
    "    return sum(misclassified)*100./len(misclassified)\n",
    "        \n",
    "def run_1_vs_5(train, test):\n",
    "    train_subset = train.loc[train.digit.isin([1, 5])]\n",
    "    X_in = train_subset.iloc[:, 1:]\n",
    "    y_in = train_subset.iloc[:, 0]\n",
    "\n",
    "    test_subset = test.loc[test.digit.isin([1, 5])]\n",
    "    X_out = test_subset.iloc[:, 1:]\n",
    "    y_out = test_subset.iloc[:, 0]\n",
    "    \n",
    "    for Q_val in [2, 5]:\n",
    "        for C_val in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "            classifier = svm.SVC(C=C_val, # Penalty parameter C of the error term.\n",
    "                                kernel='poly', # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used\n",
    "                                degree=Q_val, # Degree of the polynomial kernel, ignored by others\n",
    "                                gamma=1.0, # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "                                coef0=1.0, # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "                                shrinking=False, # Whether to use the shrinking heuristic.\n",
    "                                probability=False, # Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.\n",
    "                                tol=0.001, # Tolerance for stopping criterion.\n",
    "                                cache_size=200, # Specify the size of the kernel cache (in MB).\n",
    "                                class_weight=None, \n",
    "                                verbose=False, \n",
    "                                max_iter=-1, \n",
    "                                decision_function_shape='ovr', # Whether to return a one-vs-rest (‘ovo’) ecision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.18.\n",
    "                                random_state=None)\n",
    "\n",
    "            classifier.fit(X_in, y_in)\n",
    "            E_in = computeError(classifier, X_in, y_in)\n",
    "            E_out = computeError(classifier, X_out, y_out)\n",
    "            print \"Q: {}, C: {:.4f}, SV_s: {}, E_in: {:.2f}, E_out: {:.2f}\".format(Q_val, C_val, classifier.n_support_, E_in, E_out)\n",
    "\n",
    "run_1_vs_5(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7291\n",
      "6561 6561\n",
      "730 730\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "6562 6562\n",
      "729 729\n",
      "\n",
      "[60.0, 57.201646090534979, 54.320987654320987, 65.843621399176953, 68.724279835390945, 61.454046639231827, 65.02057613168725, 60.493827160493829, 63.923182441700959, 58.436213991769549]\n",
      "61.5418381344\n"
     ]
    }
   ],
   "source": [
    "classifier = svm.SVC(C=.01, # Penalty parameter C of the error term.\n",
    "                    kernel='poly', # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used\n",
    "                    degree=2, # Degree of the polynomial kernel, ignored by others\n",
    "                    gamma=1.0, # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "                    coef0=1.0, # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "                    shrinking=False, # Whether to use the shrinking heuristic.\n",
    "                    probability=False, # Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.\n",
    "                    tol=0.001, # Tolerance for stopping criterion.\n",
    "                    cache_size=200, # Specify the size of the kernel cache (in MB).\n",
    "                    class_weight=None, \n",
    "                    verbose=False, \n",
    "                    max_iter=-1, \n",
    "                    decision_function_shape='ovr', # Whether to return a one-vs-rest (‘ovo’) ecision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.18.\n",
    "                    random_state=None)\n",
    "E_CV_s = []\n",
    "skf = cross_validation.KFold(len(y_in), n_folds=10)\n",
    "print len(X_in)\n",
    "for train_ind, test_ind in skf:\n",
    "    print len(train_ind), len(X_in.iloc[train_ind, :])\n",
    "    print len(test_ind), len(X_in.iloc[test_ind, :])\n",
    "    print\n",
    "    classifier.fit(X_in.iloc[train_ind, :], y_in[train_ind])\n",
    "    E_CV_s.append(computeError(classifier, X_in.iloc[test_ind, :], y_in[test_ind]))\n",
    "print E_CV_s\n",
    "E_cv = float(sum(E_CV_s))/len(E_CV_s)\n",
    "print E_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of train 7291\n",
      "Len of train subset 1561\n",
      "Len of X_in and y_in 1561 1561\n",
      "0.001 100 0.448309652131\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "def computeError(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    misclassified = y_pred != y\n",
    "    return sum(misclassified)*100./len(misclassified)\n",
    "\n",
    "def run_1_vs_5_with_CF(train, test):\n",
    "    train_subset = train.loc[train.digit.isin([1, 5])]\n",
    "    X_in = train_subset.iloc[:, 1:]\n",
    "    y_in = train_subset.iloc[:, 0]\n",
    "\n",
    "    print \"Len of train\", (len(train))\n",
    "    print \"Len of train subset\", len(train_subset)\n",
    "    print \"Len of X_in and y_in\", len(X_in), len(y_in)\n",
    "    \n",
    "    test_subset = test.loc[test.digit.isin([1, 5])]\n",
    "    X_out = test_subset.iloc[:, 1:]\n",
    "    y_out = test_subset.iloc[:, 0]\n",
    "    \n",
    "    Q_val = 2\n",
    "    chosen = {}\n",
    "    for i in range(100):\n",
    "        chosen_C = None\n",
    "        chosen_E_cv = None\n",
    "        for C_val in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "            classifier = svm.SVC(C=C_val, # Penalty parameter C of the error term.\n",
    "                                kernel='poly', # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used\n",
    "                                degree=Q_val, # Degree of the polynomial kernel, ignored by others\n",
    "                                gamma=1.0, # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "                                coef0=1.0, # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "                                shrinking=False, # Whether to use the shrinking heuristic.\n",
    "                                probability=False, # Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.\n",
    "                                tol=0.001, # Tolerance for stopping criterion.\n",
    "                                cache_size=200, # Specify the size of the kernel cache (in MB).\n",
    "                                class_weight=None, \n",
    "                                verbose=False, \n",
    "                                max_iter=-1, \n",
    "                                decision_function_shape='ovr', # Whether to return a one-vs-rest (‘ovo’) ecision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.18.\n",
    "                                random_state=None)\n",
    "            E_CV_s = []\n",
    "            skf = cross_validation.KFold(len(y_in), n_folds=10)\n",
    "            for train_ind, test_ind in skf:\n",
    "                classifier.fit(X_in.iloc[train_ind, :], y_in.iloc[train_ind])\n",
    "                E_CV_s.append(computeError(classifier, X_in.iloc[test_ind, :], y_in.iloc[test_ind]))\n",
    "            E_cv = float(sum(E_CV_s))/len(E_CV_s)\n",
    "            if chosen_C is None or chosen_E_cv > E_cv:\n",
    "                chosen_C = C_val\n",
    "                chosen_E_cv = E_cv\n",
    "        if chosen_C not in chosen:\n",
    "            chosen[chosen_C] = []\n",
    "        chosen[chosen_C].append(chosen_E_cv)\n",
    "    for k, v in chosen.iteritems():\n",
    "        print k, len(v), sum(v)*1./len(v)\n",
    "\n",
    "run_1_vs_5_with_CF(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.0100, SV_s: [200 203], E_in: 0.38, E_out: 2.36\n",
      "C: 1.0000, SV_s: [14 17], E_in: 0.45, E_out: 2.12\n",
      "C: 100.0000, SV_s: [ 8 14], E_in: 0.32, E_out: 1.89\n",
      "C: 10000.0000, SV_s: [ 7 12], E_in: 0.26, E_out: 2.36\n",
      "C: 1000000.0000, SV_s: [8 9], E_in: 0.06, E_out: 2.36\n"
     ]
    }
   ],
   "source": [
    "def computeError(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    misclassified = y_pred != y\n",
    "    return sum(misclassified)*100./len(misclassified)\n",
    "        \n",
    "def run_1_vs_5_RBF(train, test):\n",
    "    train_subset = train.loc[train.digit.isin([1, 5])]\n",
    "    X_in = train_subset.iloc[:, 1:]\n",
    "    y_in = train_subset.iloc[:, 0]\n",
    "\n",
    "    test_subset = test.loc[test.digit.isin([1, 5])]\n",
    "    X_out = test_subset.iloc[:, 1:]\n",
    "    y_out = test_subset.iloc[:, 0]\n",
    "    \n",
    "    for C_val in [0.01, 1, 100, 10 ** 4, 10 ** 6]:\n",
    "        classifier = svm.SVC(C=C_val, # Penalty parameter C of the error term.\n",
    "                            kernel='rbf', # It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used\n",
    "                            gamma=1.0, # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "                            shrinking=False, # Whether to use the shrinking heuristic.\n",
    "                            probability=False, # Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.\n",
    "                            decision_function_shape='ovr', # Whether to return a one-vs-rest (‘ovo’) ecision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.18.\n",
    "                            )\n",
    "        classifier.fit(X_in, y_in)\n",
    "        E_in = computeError(classifier, X_in, y_in)\n",
    "        E_out = computeError(classifier, X_out, y_out)\n",
    "        print \"C: {:.4f}, SV_s: {}, E_in: {:.2f}, E_out: {:.2f}\".format(C_val, classifier.n_support_, E_in, E_out)\n",
    "\n",
    "run_1_vs_5_RBF(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
